<!DOCTYPE html>
<html lang="ko">
<head>
  <meta charset="UTF-8" />
  <title>Live2D Viewer</title>

  <!-- PixiJS: 2D ê·¸ë˜í”½ ë Œë”ë§ ë¼ì´ë¸ŒëŸ¬ë¦¬ -->
  <script src="https://cdnjs.cloudflare.com/ajax/libs/pixi.js/6.5.10/browser/pixi.min.js"></script>

  <!-- Live2D Cubism Core ë¼ì´ë¸ŒëŸ¬ë¦¬ -->
  <script src="https://cdn.jsdelivr.net/npm/live2dcubismcore@1.0.2/live2dcubismcore.min.js"></script>

  <!-- pixi-live2d-display: Live2D ëª¨ë¸ì„ PixiJSì— ì—°ê²°í•´ì£¼ëŠ” ë¼ì´ë¸ŒëŸ¬ë¦¬ -->
  <script src="https://unpkg.com/pixi-live2d-display@0.4.0/dist/cubism4.min.js"></script>
</head>

<style>
  canvas {
    height: 500px;
    object-fit: cover;
  }
</style>

<body style="margin: 0; overflow: hidden; background-color: #282c34">
  <!-- Live2D ëª¨ë¸ì´ ë Œë”ë§ë  ìº”ë²„ìŠ¤ -->
  <canvas id="canvas" style="margin-top: 100px"></canvas>

  <script>
    // 1ï¸âƒ£ PixiJS ì• í”Œë¦¬ì¼€ì´ì…˜ ìƒì„±
    const app = new PIXI.Application({
      view: document.getElementById("canvas"),
      width: window.innerWidth,
      height: window.innerHeight,
      backgroundColor: 0x282c34,
      resizeTo: window,
    });

    let model;  // ë‚˜ì¤‘ì— ë¡œë“œí•œ Live2D ëª¨ë¸ì„ ì €ì¥í•  ë³€ìˆ˜

    // 2ï¸âƒ£ Live2D ëª¨ë¸ ë¡œë“œ
    PIXI.live2d.Live2DModel.from(
      "./model/haru/runtime/haru_greeter_t05.model3.json"  // ëª¨ë¸ ê²½ë¡œ
    ).then((loadedModel) => {
      model = loadedModel;
      model.scale.set(0.5);  // ëª¨ë¸ í¬ê¸° ì¡°ì ˆ
      model.x = app.renderer.width / 2.5;  // X ìœ„ì¹˜ ì¡°ì •
      model.y = app.renderer.height * 1.5; // Y ìœ„ì¹˜ ì¡°ì •
      model.anchor.set(0.5, 0.5);  // ì¤‘ì‹¬ ê¸°ì¤€ ì„¤ì •
      app.stage.addChild(model);   // í™”ë©´ì— ì¶”ê°€

      startVolumeSync();  // ğŸ“¢ ë³¼ë¥¨ ê¸°ë°˜ ë¦½ì‹±í¬ ì‹œì‘
    });

    // 3ï¸âƒ£ (ì˜ˆì‹œìš©) ë¸Œë¼ìš°ì € ê¸°ë³¸ TTSì™€ ëœë¤ ë¦½ì‹±í¬ ì—°ë™
    function speak(text) {
      const utterance = new SpeechSynthesisUtterance(text);
      utterance.lang = "ko-KR";

      // ğŸ“Œ ì… ê°€ë¡œ ê¸¸ì´ ì¡°ì •: 'ã…£', 'ã…', 'e', 'i' ë“± í¬í•¨ ì—¬ë¶€
      const widenMouthIfNeeded = (text) => {
        const wideSounds = ["i", "e", "ã…£", "ã…”", "ã…"];
        const narrowSounds = ["o", "u", "ã…—", "ã…œ", "ã…¡"];
        const lower = text.toLowerCase();

        let widen = wideSounds.some(v => lower.includes(v));
        let narrow = narrowSounds.some(v => lower.includes(v));

        if (model) {
          const value = widen ? 1.0 : narrow ? 0.0 : 0.5;
          model.internalModel.coreModel.setParameterValueById("ParamMouthForm", value);
        }
      };

      utterance.onstart = () => {
        widenMouthIfNeeded(text);
      };

      utterance.onend = () => {
        if (model) {
          model.internalModel.coreModel.setParameterValueById("ParamMouthForm", 0.5);  // ì¤‘ë¦½ìœ¼ë¡œ
          model.internalModel.coreModel.setParameterValueById("ParamMouthOpenY", 0);   // ì… ë‹¤ë¬¼ê¸°
        }
      };

      window.speechSynthesis.speak(utterance);
    }


    // 5ï¸âƒ£ ë³¼ë¥¨ ê¸°ë°˜ ë¦½ì‹±í¬: backend/volume.json íŒŒì¼ì„ 50msë§ˆë‹¤ ì½ì–´ì„œ ì…ëª¨ì–‘ ì œì–´
    function startVolumeSync() {
      setInterval(async () => {
        try {
          // ğŸ“¥ volume.jsonì„ fetch (ìºì‹œ ë°©ì§€ìš© timestamp ì¶”ê°€)
          const res = await fetch("volume.json?_=" + Date.now());
          if (!res.ok) return;
          const { volume } = await res.json();  // { "volume": 0.123 }

          if (model && typeof volume === "number") {
            // ğŸ”„ ë³¼ë¥¨ê°’ì„ ParamMouthOpenYì— ë°˜ì˜ (0.01 ì´í•˜ë©´ ì… ë‹«ê¸°)
            const mouthValue = volume > 0.01 ? Math.min(volume * 4.0, 1.0) : 0;
            model.internalModel.coreModel.setParameterValueById(
              "ParamMouthOpenY",
              mouthValue
            );
          }
        } catch (e) {
          console.warn("ë³¼ë¥¨ ë™ê¸°í™” ì‹¤íŒ¨:", e);
        }
      }, 50);  // ğŸ” 50ms ì£¼ê¸° (20fps ìˆ˜ì¤€)
    }
  </script>

  <!-- ë²„íŠ¼ í´ë¦­ ì‹œ speak í•¨ìˆ˜ í˜¸ì¶œ -->
  <button onclick="speak('ì•ˆë…•í•˜ì„¸ìš”. ì €ëŠ” í•˜ë£¨ì—ìš”!')">Haruê°€ ë§í•˜ê¸°</button>
</body>
</html>
